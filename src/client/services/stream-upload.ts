import { stat } from "fs/promises";
import { basename } from "path";
import cliProgress from "cli-progress";
import { calculateChecksumFromFile } from "../../utils/checksum";

/**
 * æµå¼ä¸Šä¼ æ–‡ä»¶ï¼ˆæ”¯æŒçœŸå®è¿›åº¦ï¼‰
 */
export async function uploadFileStream(
  filePath: string,
  serverUrl: string,
  authToken: string,
  env: string,
  skipChecksum: boolean = false,
  shouldExtract: boolean = false
): Promise<any> {
  try {
    // è·å–æ–‡ä»¶å¤§å°
    const stats = await stat(filePath);
    const fileSize = stats.size;

    // å…ˆè¾“å‡ºæ‰€æœ‰ä¿¡æ¯ï¼Œå†å¼€å§‹è¿›åº¦æ¡
    console.log(`\nğŸ“„ Uploading file (streaming): ${basename(filePath)}`);
    console.log(`ğŸš€ Uploading to ${serverUrl}...`);
    console.log(`ğŸ“¦ File size: ${(fileSize / 1024 / 1024).toFixed(2)} MB`);

    // è®¡ç®—æ–‡ä»¶æ ¡éªŒå’Œ
    let checksum = "";
    if (!skipChecksum) {
      console.log(`ğŸ” Calculating checksum...`);
      checksum = await calculateChecksumFromFile(filePath);
      console.log(`âœ… Checksum (SHA256): ${checksum.substring(0, 16)}...`);
    } else {
      console.log(`â­ï¸  Skipping checksum verification`);
    }

    // è¯»å–æ–‡ä»¶ä¸º Blob
    const file = Bun.file(filePath);
    const blob = await file.arrayBuffer();

    // åˆ›å»ºè¿›åº¦æ¡
    const progressBar = new cliProgress.SingleBar({
      format:
        "ğŸ“¤ [{bar}] {percentage}% | {uploadedMB}/{totalMB} MB | {speed} | ETA: {eta}s",
      barCompleteChar: "\u2588",
      barIncompleteChar: "\u2591",
      hideCursor: true,
    });

    const totalMB = (blob.byteLength / 1024 / 1024).toFixed(2);
    progressBar.start(blob.byteLength, 0, {
      uploadedMB: "0.00",
      totalMB: totalMB,
      speed: "0 KB/s",
      eta: "0",
    });

    const startTime = Date.now();

    // åˆ›å»ºå¯è¯»æµå¹¶è·Ÿè¸ªè¿›åº¦
    let uploadedBytes = 0;
    const stream = new ReadableStream({
      async start(controller) {
        const chunkSize = 64 * 1024; // 64KB chunks
        const uint8Array = new Uint8Array(blob);

        for (let i = 0; i < uint8Array.length; i += chunkSize) {
          const chunk = uint8Array.slice(
            i,
            Math.min(i + chunkSize, uint8Array.length)
          );
          controller.enqueue(chunk);

          uploadedBytes += chunk.length;

          // è®¡ç®—é€Ÿåº¦
          const elapsed = Math.max((Date.now() - startTime) / 1000, 0.001);
          const bytesPerSecond = uploadedBytes / elapsed;

          // åŠ¨æ€é€Ÿåº¦å•ä½
          let speedText: string;
          if (bytesPerSecond < 1024 * 1024) {
            speedText = `${(bytesPerSecond / 1024).toFixed(0)} KB/s`;
          } else if (bytesPerSecond < 1024 * 1024 * 1024) {
            speedText = `${(bytesPerSecond / (1024 * 1024)).toFixed(2)} MB/s`;
          } else {
            speedText = `${(bytesPerSecond / (1024 * 1024 * 1024)).toFixed(
              2
            )} GB/s`;
          }

          // è®¡ç®—ETA
          const remainingBytes = blob.byteLength - uploadedBytes;
          const eta = (remainingBytes / Math.max(bytesPerSecond, 1)).toFixed(0);

          progressBar.update(uploadedBytes, {
            uploadedMB: (uploadedBytes / 1024 / 1024).toFixed(2),
            totalMB: totalMB,
            speed: speedText,
            eta: eta,
          });

          // æ¨¡æ‹Ÿç½‘ç»œå»¶è¿Ÿï¼Œè®©è¿›åº¦æ¡å¯è§
          // await new Promise((resolve) => setTimeout(resolve, 10));
        }

        controller.close();
        progressBar.stop();
      },
    });

    // æ„å»ºæŸ¥è¯¢å‚æ•°
    const queryParams = new URLSearchParams({
      env,
      fileName: basename(filePath),
      shouldExtract: shouldExtract.toString(),
    });

    if (checksum) {
      queryParams.set("checksum", checksum);
    }

    // åªä¿ç•™è®¤è¯ä¿¡æ¯åœ¨header
    const headers: Record<string, string> = {
      authorization: authToken,
      "Content-Type": "application/octet-stream",
      "Content-Length": blob.byteLength.toString(),
    };

    // å‘é€æµå¼è¯·æ±‚
    const response = await fetch(`${serverUrl}/upload-stream?${queryParams}`, {
      method: "POST",
      headers,
      body: stream,
      duplex: "half" as any,
    });

    const responseText = await response.text();
    let result;

    try {
      result = JSON.parse(responseText);
    } catch {
      result = { raw: responseText };
    }

    if (!response.ok) {
      throw new Error(
        `Server responded with ${response.status}: ${
          result.error || responseText
        }`
      );
    }

    // å®Œæˆåè¾“å‡ºï¼ˆè¿›åº¦æ¡å·²ç»æ¢è¡Œäº†ï¼‰
    console.log(`âœ… Upload completed successfully!`);
    return result;
  } catch (error: any) {
    // é”™è¯¯è¾“å‡ºè¦æ¢è¡Œï¼Œå› ä¸ºå¯èƒ½åœ¨è¿›åº¦æ¡ä¸­é—´
    console.error(`\nâŒ Upload failed:`, error.message);
    throw error;
  }
}

/**
 * æµå¼ä¸Šä¼ ç›®å½•ï¼ˆå…ˆå‹ç¼©ï¼Œå†æµå¼ä¸Šä¼ ï¼‰
 */
export async function uploadDirectoryStream(
  dirPath: string,
  serverUrl: string,
  authToken: string,
  env: string,
  excludePatterns: string[] = [],
  skipChecksum: boolean = false
): Promise<any> {
  const { createZipArchive } = await import("./archive");
  const { rm } = await import("fs/promises");
  const { tmpdir } = await import("os");
  const { join } = await import("path");

  const tempZipPath = join(tmpdir(), `deploy-${env}-${Date.now()}.zip`);

  try {
    console.log(`\nğŸ“ Preparing directory for upload: ${dirPath}`);

    // å‹ç¼©ç›®å½•
    await createZipArchive(dirPath, tempZipPath, excludePatterns);

    // ä½¿ç”¨æµå¼ä¸Šä¼ å‹ç¼©æ–‡ä»¶ï¼ˆéœ€è¦è§£å‹ï¼‰
    const result = await uploadFileStream(
      tempZipPath,
      serverUrl,
      authToken,
      env,
      skipChecksum,
      true // ç›®å½•å‹ç¼©åéœ€è¦è§£å‹
    );

    return result;
  } catch (error: any) {
    console.error(`âŒ Upload failed:`, error.message);
    throw error;
  } finally {
    // æ¸…ç†ä¸´æ—¶å‹ç¼©æ–‡ä»¶
    try {
      await rm(tempZipPath, { force: true });
    } catch {}
  }
}
