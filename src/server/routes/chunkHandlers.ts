import { createHash } from "crypto";
import type { ServerConfig } from "../types";
import { validateRequest, verifyFileChecksum } from "../services/validation";
import { extractAndDeploy, saveFile } from "../services/deployment";
import {
  initUpload,
  getUploadStatus,
  saveChunk,
  mergeChunks,
  deleteUpload,
} from "../services/chunkStorage";

/**
 * GET /upload/status - æŸ¥è¯¢ä¸Šä¼ çŠ¶æ€
 */
export async function handleUploadStatus(
  req: Request,
  config: ServerConfig
): Promise<Response> {
  const url = new URL(req.url);
  const uploadId = url.searchParams.get("uploadId");
  const env = url.searchParams.get("env");
  const authToken = req.headers.get("authorization");

  if (!uploadId) {
    return Response.json({ error: "Missing uploadId" }, { status: 400 });
  }

  // éªŒè¯è¯·æ±‚
  const validation = validateRequest(env, authToken, config);
  if (!validation.valid) {
    return Response.json(
      { error: validation.error },
      { status: validation.error?.includes("token") ? 403 : 400 }
    );
  }

  const status = await getUploadStatus(uploadId);
  return Response.json(status);
}

/**
 * POST /upload/init - åˆå§‹åŒ–ä¸Šä¼ ä»»åŠ¡
 */
export async function handleUploadInit(
  req: Request,
  config: ServerConfig
): Promise<Response> {
  try {
    const body = (await req.json()) as {
      uploadId: string;
      totalChunks: number;
      fileName: string;
      checksum?: string;
      shouldExtract: boolean;
      env: string;
    };

    const authToken = req.headers.get("authorization");

    // éªŒè¯è¯·æ±‚
    const validation = validateRequest(body.env, authToken, config);
    if (!validation.valid) {
      return Response.json(
        { error: validation.error },
        { status: validation.error?.includes("token") ? 403 : 400 }
      );
    }

    console.log(`\nğŸ“¦ Initializing chunk upload: ${body.uploadId}`);
    console.log(`   ğŸ“„ File: ${body.fileName}`);
    console.log(`   ğŸ“Š Total chunks: ${body.totalChunks}`);

    const metadata = await initUpload(
      body.uploadId,
      body.totalChunks,
      body.env,
      body.shouldExtract
    );

    return Response.json({
      success: true,
      uploadId: body.uploadId,
      uploadedChunks: metadata.uploadedChunks,
      totalChunks: metadata.totalChunks,
      isResume: metadata.uploadedChunks.length > 0,
    });
  } catch (error: any) {
    console.error("âŒ Upload init failed:", error);
    return Response.json(
      { error: "Init failed", details: error.message },
      { status: 500 }
    );
  }
}

/**
 * POST /upload/chunk - ä¸Šä¼ å•ä¸ªåˆ†ç‰‡
 */
export async function handleUploadChunk(
  req: Request,
  config: ServerConfig
): Promise<Response> {
  try {
    const url = new URL(req.url);
    const uploadId = url.searchParams.get("uploadId");
    const chunkIndexStr = url.searchParams.get("chunkIndex");
    const env = url.searchParams.get("env");
    const authToken = req.headers.get("authorization");

    if (!uploadId || chunkIndexStr === null) {
      return Response.json(
        { error: "Missing uploadId or chunkIndex" },
        { status: 400 }
      );
    }

    // éªŒè¯è¯·æ±‚
    const validation = validateRequest(env, authToken, config);
    if (!validation.valid) {
      return Response.json(
        { error: validation.error },
        { status: validation.error?.includes("token") ? 403 : 400 }
      );
    }

    const chunkIndex = parseInt(chunkIndexStr);
    const body = req.body;
    if (!body) {
      return Response.json({ error: "No chunk data" }, { status: 400 });
    }

    // è¯»å–åˆ†ç‰‡æ•°æ®
    const reader = body.getReader();
    const chunks: Uint8Array[] = [];
    while (true) {
      const { done, value } = await reader.read();
      if (done) break;
      chunks.push(value);
    }
    const buffer = Buffer.concat(chunks);

    // éªŒè¯åˆ†ç‰‡ MD5ï¼ˆå¦‚æœæä¾›ï¼‰
    const expectedMd5 = req.headers.get("x-chunk-md5");
    if (expectedMd5) {
      const actualMd5 = createHash("md5").update(buffer).digest("hex");
      if (actualMd5 !== expectedMd5) {
        console.error(
          `âŒ Chunk ${chunkIndex} MD5 mismatch: expected ${expectedMd5}, got ${actualMd5}`
        );
        return Response.json(
          { error: "Chunk MD5 verification failed", chunkIndex },
          { status: 400 }
        );
      }
    }

    // ä¿å­˜åˆ†ç‰‡
    const result = await saveChunk(uploadId, chunkIndex, buffer);

    return Response.json(result);
  } catch (error: any) {
    console.error("âŒ Chunk upload failed:", error);
    return Response.json(
      { error: "Chunk upload failed", details: error.message },
      { status: 500 }
    );
  }
}

/**
 * POST /upload/complete - å®Œæˆä¸Šä¼ å¹¶åˆå¹¶
 */
export async function handleUploadComplete(
  req: Request,
  config: ServerConfig
): Promise<Response> {
  try {
    const body = (await req.json()) as {
      uploadId: string;
      fileName: string;
      checksum?: string;
      shouldExtract: boolean;
      env: string;
    };

    const authToken = req.headers.get("authorization");

    // éªŒè¯è¯·æ±‚
    const validation = validateRequest(body.env, authToken, config);
    if (!validation.valid) {
      return Response.json(
        { error: validation.error },
        { status: validation.error?.includes("token") ? 403 : 400 }
      );
    }

    console.log(`\nâœ… Completing upload: ${body.uploadId}`);

    // åˆå¹¶åˆ†ç‰‡
    const buffer = await mergeChunks(body.uploadId);
    console.log(
      `ğŸ“¦ Merged file size: ${(buffer.length / 1024 / 1024).toFixed(2)} MB`
    );

    // æ ¡éªŒæ–‡ä»¶å®Œæ•´æ€§
    const checksumResult = verifyFileChecksum(buffer, body.checksum || null);
    if (checksumResult.error) {
      // æ ¡éªŒå¤±è´¥ï¼Œåˆ é™¤ä¸Šä¼ ä»»åŠ¡
      await deleteUpload(body.uploadId);
      return checksumResult.error;
    }
    const checksumVerified = checksumResult.verified;

    // å¤„ç†æ–‡ä»¶
    if (body.shouldExtract) {
      await extractAndDeploy(
        buffer,
        body.fileName,
        validation.envConfig!,
        body.env
      );
    } else {
      await saveFile(buffer, body.fileName, validation.envConfig!, body.env);
    }

    // æˆåŠŸååˆ é™¤ä¸Šä¼ ä»»åŠ¡
    await deleteUpload(body.uploadId);

    console.log(`âœ… Upload completed and cleaned up`);

    return Response.json({
      success: true,
      message: "File uploaded and processed successfully",
      fileName: body.fileName,
      fileSize: buffer.length,
      checksumVerified,
      extracted: body.shouldExtract,
      uploadPath: validation.envConfig!.uploadPath,
    });
  } catch (error: any) {
    console.error("âŒ Upload complete failed:", error);
    return Response.json(
      { error: "Upload complete failed", details: error.message },
      { status: 500 }
    );
  }
}

/**
 * DELETE /upload - å–æ¶ˆä¸Šä¼ 
 */
export async function handleUploadCancel(
  req: Request,
  config: ServerConfig
): Promise<Response> {
  try {
    const url = new URL(req.url);
    const uploadId = url.searchParams.get("uploadId");
    const env = url.searchParams.get("env");
    const authToken = req.headers.get("authorization");

    if (!uploadId) {
      return Response.json({ error: "Missing uploadId" }, { status: 400 });
    }

    // éªŒè¯è¯·æ±‚
    const validation = validateRequest(env, authToken, config);
    if (!validation.valid) {
      return Response.json(
        { error: validation.error },
        { status: validation.error?.includes("token") ? 403 : 400 }
      );
    }

    await deleteUpload(uploadId);
    console.log(`ğŸ—‘ï¸ Upload cancelled: ${uploadId}`);

    return Response.json({ success: true, message: "Upload cancelled" });
  } catch (error: any) {
    return Response.json(
      { error: "Cancel failed", details: error.message },
      { status: 500 }
    );
  }
}
